# User Research Plan for Thesis User Studies

## Research Objectives

### Primary Objective
Evaluate the effectiveness of the notification system in improving accessibility to NOAA National Water Model data for recreational water users and measure the impact on user behavior and decision-making.

### Secondary Objectives
1. Assess usability and user experience of the notification system
2. Identify optimal notification content and delivery methods
3. Measure user engagement with automated flow alerts
4. Understand user mental models for interpreting flow data
5. Validate threshold setting and customization approaches
6. Document accessibility improvements achieved through the system

## Research Questions

### Primary Research Questions
1. **Accessibility Impact**: How does the notification system improve user access to NOAA flow data compared to manual checking?
2. **Behavioral Change**: Do users modify their water activity planning and safety behaviors based on automated notifications?
3. **Usability**: Can users successfully configure and manage notification preferences?

### Secondary Research Questions
1. What notification frequency and content types provide optimal user value?
2. How do users interpret and act upon different types of flow alerts?
3. What threshold-setting approaches are most intuitive for users?
4. How does notification effectiveness vary across different user experience levels?
5. What barriers exist to notification system adoption and use?

## Study Design

### Research Approach
**Mixed-Methods Design**: Combining quantitative usage metrics with qualitative user feedback to provide comprehensive evaluation of the notification system.

### Study Timeline
- **Recruitment Phase**: 1 week
- **Pre-study Interviews**: 1 week
- **System Usage Period**: 2 weeks
- **Post-study Evaluation**: 1 week
- **Data Analysis**: 1 week

## Participant Recruitment

### Target Population
Recreational water users who actively use flow information for planning outdoor activities.

### Inclusion Criteria
- **Age**: 18 years or older
- **Activity Level**: Regular participation in water-based recreation (minimum 2x per month)
- **Technology Use**: Smartphone users comfortable with mobile apps
- **Information Seeking**: Current users of flow/weather information for planning
- **Geographic Location**: Access to rivers with NOAA monitoring stations

### Exclusion Criteria
- Professional water industry workers (to focus on recreational use)
- Users without consistent mobile data access
- Participants in other concurrent research studies

### Sample Size and Composition
- **Target**: 12-15 participants
- **Experience Distribution**:
  - Novice users (1-2 years experience): 4-5 participants
  - Intermediate users (3-7 years experience): 4-5 participants
  - Expert users (8+ years experience): 4-5 participants
- **Activity Distribution**:
  - Fishing: 4-5 participants
  - Kayaking/Paddling: 4-5 participants
  - Mixed activities: 4-5 participants

### Recruitment Strategy
- **Local Outdoor Clubs**: Partner with fishing and paddling organizations
- **Outdoor Retailers**: Recruitment flyers at gear shops
- **Social Media**: Targeted posts in local recreation groups
- **University Networks**: Campus recreation and outdoor programs
- **Snowball Sampling**: Participant referrals

## Data Collection Methods

### 1. Pre-Study Interview (30-45 minutes)
**Purpose**: Establish baseline behavior and preferences

**Interview Topics**:
- Current information-seeking behavior for water activities
- Existing apps and tools used for flow information
- Decision-making process for activity planning
- Safety considerations and information needs
- Technology comfort level and notification preferences
- Experience with flow data interpretation

**Data Collection**:
- Audio recording (with consent)
- Interview notes
- Demographic questionnaire

### 2. System Usage Period (2 weeks)
**Purpose**: Natural use of notification system with minimal researcher intervention

**User Tasks**:
- Install enhanced Rivr app with notifications
- Complete initial notification setup
- Configure thresholds for preferred activities
- Use system naturally for 2-week period
- Optional: Log activities and decisions influenced by notifications

**Automated Data Collection**:
- Notification delivery and open rates
- App usage patterns and screen time
- Threshold creation and modification behavior
- Feature usage analytics

### 3. Post-Study Evaluation (60-90 minutes)
**Purpose**: Comprehensive assessment of user experience and system impact

**Components**:
- **Usability Testing (20 minutes)**: Structured tasks using System Usability Scale
- **User Interview (40 minutes)**: Semi-structured discussion of experience
- **Questionnaire (20 minutes)**: Standardized feedback forms
- **System Demonstration (10 minutes)**: User shows personalized setup

## Measurement Instruments

### Quantitative Measures

#### System Usability Scale (SUS)
- Standardized 10-item questionnaire
- Scores system overall usability (0-100 scale)
- Industry benchmark comparison available

#### Custom Notification Effectiveness Scale
Likert scale items (1-7):
1. "The notifications helped me stay informed about river conditions"
2. "I was able to easily set up notifications for my preferred activities"
3. "The notification content was clear and actionable"
4. "The notifications improved my activity planning"
5. "I trust the accuracy of the notification information"
6. "The notification frequency was appropriate for my needs"
7. "The notifications enhanced my safety awareness"

#### Usage Analytics
- Notification delivery success rate
- Notification open rate and response time
- Number of thresholds created per user
- App session frequency and duration
- Feature usage distribution

### Qualitative Measures

#### Semi-Structured Interview Guide
**Accessibility and Value**:
- How did notifications change your information-seeking behavior?
- What value did you get from automated alerts vs. manual checking?
- Were there situations where notifications were particularly helpful?

**Usability and Experience**:
- Walk me through setting up your first notification
- What was confusing or unclear about the system?
- How did you decide what thresholds to set?

**Content and Delivery**:
- Tell me about a notification that led you to take action
- Were there notifications that weren't useful? Why?
- How would you improve the notification content?

**Behavioral Impact**:
- Did notifications influence your activity planning? How?
- Any safety situations where notifications were important?
- Changes in confidence or comfort level with flow information?

**Future Use**:
- Would you continue using this system? Why/why not?
- What features would make it more valuable?
- Would you recommend it to other outdoor enthusiasts?

#### Observational Data
- User behavior during usability tasks
- Error patterns and recovery strategies
- Emotional responses to system features
- Spontaneous comments during use

## Data Analysis Plan

### Quantitative Analysis
- **Descriptive Statistics**: Means, medians, ranges for all scale measures
- **Usability Benchmarking**: SUS scores compared to industry standards
- **Usage Pattern Analysis**: Correlation between demographics and system use
- **Effectiveness Metrics**: Pre/post comparison of information access behavior

### Qualitative Analysis
- **Thematic Analysis**: Coding interview transcripts for recurring themes
- **User Journey Mapping**: Understanding touchpoints and pain points
- **Persona Development**: Identifying distinct user types and needs
- **Barrier Identification**: Cataloging obstacles to system adoption

### Mixed Methods Integration
- **Triangulation**: Compare quantitative metrics with qualitative feedback
- **Explanation**: Use qualitative data to explain quantitative findings
- **Contradiction Analysis**: Explore discrepancies between data sources

## Ethical Considerations

### IRB Approval
- Submit study protocol to Institutional Review Board
- Address privacy, consent, and data handling procedures
- Plan for participant withdrawal and data deletion

### Informed Consent
- Clear explanation of study purpose and procedures
- Voluntary participation with right to withdraw
- Data use permissions and anonymization
- Compensation details (if applicable)

### Privacy Protection
- Anonymized data collection and storage
- Secure data handling procedures
- Limited access to personally identifiable information
- Clear data retention and deletion policies

### Participant Safety
- Emphasis that app is for research, not safety-critical decisions
- Disclaimers about data accuracy and limitations
- Emergency contact information for technical issues
- Clear boundaries between research and app support

## Expected Outcomes

### Academic Contributions
- **Usability Insights**: Best practices for scientific data notification systems
- **Behavioral Understanding**: How users respond to automated environmental alerts
- **Accessibility Metrics**: Quantified improvements in data access
- **Design Guidelines**: Recommendations for similar systems

### Practical Applications
- **System Validation**: Evidence of notification system effectiveness
- **User Requirements**: Detailed understanding of user needs and preferences
- **Feature Prioritization**: Data-driven decisions for future development
- **Adoption Strategies**: Insights for encouraging system use

## Risk Mitigation

### Recruitment Challenges
- **Multiple Channels**: Diverse recruitment strategies to ensure sample size
- **Flexible Scheduling**: Accommodate participant availability
- **Incentives**: Appropriate compensation for time investment

### Technical Issues
- **Backup Plans**: Alternative data collection if app issues occur
- **Support Protocol**: Clear procedure for technical assistance
- **Data Recovery**: Multiple collection methods to prevent data loss

### Participant Retention
- **Clear Expectations**: Transparent communication about study requirements
- **Regular Check-ins**: Optional support during usage period
- **Flexible Participation**: Accommodate schedule changes

### Data Quality
- **Validation Checks**: Cross-reference multiple data sources
- **Pilot Testing**: Small-scale test before full study
- **Regular Monitoring**: Track data collection progress and quality

This comprehensive user research plan provides the foundation for rigorous evaluation of the notification system's impact on NOAA data accessibility while maintaining high standards for participant protection and data quality.
